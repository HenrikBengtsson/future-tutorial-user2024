[
  {
    "objectID": "lab2.html",
    "href": "lab2.html",
    "title": "Lab: Futureverse 2",
    "section": "",
    "text": "Note\n\n\n\nThis is the second of two parallelization labs. It will take you through Futureverse functions that you and others are likely to use to parallelize R code. We will cover the future.apply package, furrr package, and foreach with the doFuture package. In your R career, you can pick whichever you prefer - they are all equally good.\nYou are highly encouraged to test things out yourself and tweak things to figure out how these methods behave.\nSlides: You’ll find the slides in the menus above."
  },
  {
    "objectID": "lab2.html#setup",
    "href": "lab2.html#setup",
    "title": "Lab: Futureverse 2",
    "section": "Setup",
    "text": "Setup\nIt is assumed that you have already installed common Futureverse packages in Lab 1. In this second part, we will use a not-so-slow-but-still-slow version of slow_sum();\n\nlibrary(future)\nlibrary(progressr)\n\nslow_sum &lt;- function(x) {\n  sum &lt;- 0\n  for (value in x) {\n    Sys.sleep(0.1)     ## 0.1 second slowdown per value\n    sum &lt;- sum + value\n  }\n  sum\n}"
  },
  {
    "objectID": "lab2.html#exercises",
    "href": "lab2.html#exercises",
    "title": "Lab: Futureverse 2",
    "section": "Exercises",
    "text": "Exercises\n\nRecap from Lab 1\nIn the first part - Lab 1 - we learned about the future() and value() functions part of the future package. They allow us to run independent tasks like:\n\nxs &lt;- list(1:25, 26:50, 51:75, 76:100)\na &lt;- slow_sum(xs[[1]])\nb &lt;- slow_sum(xs[[2]])\nc &lt;- slow_sum(xs[[3]])\nd &lt;- slow_sum(xs[[4]])\ny &lt;- a + b + c + d\ny\n\n[1] 5050\n\n\nin parallel. We learned how to do:\n\nlibrary(future)\nplan(multisession, workers = 4)\n\nxs &lt;- list(1:25, 26:50, 51:75, 76:100)\nfa &lt;- future(slow_sum(xs[[1]]))\nfb &lt;- future(slow_sum(xs[[2]]))\nfc &lt;- future(slow_sum(xs[[3]]))\nfd &lt;- future(slow_sum(xs[[4]]))\ny &lt;- value(fa) + value(fb) + value(fc) + value(fd)\ny\n\n[1] 5050\n\n\nWe then learned how to generalize this to a for-loop, by realizing we can do:\n\nlibrary(future)\nplan(multisession, workers = 4)\n\nxs &lt;- list(1:25, 26:50, 51:75, 76:100)\n\nfs &lt;- list()\nfs[[1]] &lt;- future(slow_sum(xs[[1]]))\nfs[[2]] &lt;- future(slow_sum(xs[[2]]))\nfs[[3]] &lt;- future(slow_sum(xs[[3]]))\nfs[[4]] &lt;- future(slow_sum(xs[[4]]))\n\nys &lt;- list()\nys[[1]] &lt;- value(fs[[1]])\nys[[2]] &lt;- value(fs[[2]])\nys[[3]] &lt;- value(fs[[3]])\nys[[4]] &lt;- value(fs[[4]])\n\nys &lt;- unlist(ys)\ny &lt;- sum(ys)\ny\n\n[1] 5050\n\n\nand then simplify as:\n\nlibrary(future)\nplan(multisession, workers = 4)\n\nxs &lt;- list(1:25, 26:50, 51:75, 76:100)\n\nfs &lt;- list()\nfor (ii in seq_along(xs)) {\n  fs[[ii]] &lt;- future(slow_sum(xs[[ii]]))\n}\n\nys &lt;- list()\nfor (ii in seq_along(fs)) {\n  ys[[ii]] &lt;- value(fs[[ii]])\n}\n\nys &lt;- unlist(ys)\ny &lt;- sum(ys)\ny\n\n[1] 5050\n\n\nWe then got rid of the for-loops in the auxillary index ii, by using lapply():\n\nlibrary(future)\nplan(multisession, workers = 4)\n\nxs &lt;- list(1:25, 26:50, 51:75, 76:100)\n\nfs &lt;- lapply(xs, function(x) { future(slow_sum(x)) })\nys &lt;- lapply(fs, value)\n\nys &lt;- unlist(ys)\ny &lt;- sum(ys)\ny\n\n[1] 5050\n\n\nFinally, we turned this into a utility function:\n\nparallel_lapply &lt;- function(X, FUN) {\n  fs &lt;- lapply(X, function(x) {\n    future(FUN(x))\n  })\n  lapply(fs, value)\n}\n\nsuch that we can do:\n\nlibrary(future)\nplan(multisession, workers = 4)\n\nxs &lt;- list(1:25, 26:50, 51:75, 76:100)\nys &lt;- parallel_lapply(xs, slow_sum)\nys &lt;- unlist(ys)\ny &lt;- sum(ys)\ny\n\n[1] 5050\n\n\n\n\nParallel versions of purrr::map()\nTask 1:\nWrite a parallel_map() function that emulates what the map() function of the purrr package does, while at the same time running in parallel using futures. We want to create a parallel version of:\n\nlibrary(purrr)\nxs &lt;- list(1:25, 26:50, 51:75, 76:100)\nys &lt;- map(xs, slow_sum)\nys &lt;- unlist(ys)\ny &lt;- sum(ys)\ny\n\n[1] 5050\n\n\nWe want to use the same argument names as map();\n\nargs(map)\n\nfunction (.x, .f, ..., .progress = FALSE) \nNULL\n\n\nso that users of our parallel_map() will feel at home. For simplicity, you can ignore arguments ... and .progress. So, let’s create a function:\n\nparallel_map &lt;- function(.x, .f) {\n  ## something here\n}\n\nI recommend that you modify the existing parallel_lapply(). Verify that it works with:\n\nlibrary(future)\nplan(multisession, workers = 4)\n\nxs &lt;- list(1:25, 26:50, 51:75, 76:100)\nys &lt;- parallel_map(xs, slow_sum)\nys &lt;- unlist(ys)\ny &lt;- sum(ys)\ny\n\n\n\nSolution\n\n\nlibrary(purrr)\n\nparallel_map &lt;- function(.x, .f) {\n  fs &lt;- map(.x, function(x) {\n    future(.f(x))\n  })\n  map(fs, value)\n}\n\n\nTask 2:\nJust like lapply() and map() return list, parallel_lapply() and parallel_map() return lists. But, as in our example, it’s common that one wants the atomic vector version of it, which is why we do:\n\nys &lt;- unlist(ys)\nys\n\n[1]  325  950 1575 2200\n\n\nHaving to call this each time is tedious and adds friction and noise to our code. When not parallelizing, we can use purrr’s map_dbl() to achieve the same in a one go;\n\nlibrary(purrr)\nxs &lt;- list(1:25, 26:50, 51:75, 76:100)\nys &lt;- map_dbl(xs, slow_sum)\ny &lt;- sum(ys)\ny\n\n[1] 5050\n\n\nWrite your own parallel_map_dbl() that achieves the same, but via futures, so that you can run:\n\nlibrary(purrr)\nxs &lt;- list(1:25, 26:50, 51:75, 76:100)\nys &lt;- parallel_map_dbl(xs, slow_sum)\ny &lt;- sum(ys)\ny\n\nHint: Don’t use unlist() - instead make use of map_dbl(). But think carefully where in your function you want to use map_dbl().\n\n\nSolution\n\n\nlibrary(purrr)\n\nparallel_map_dbl &lt;- function(.x, .f) {\n  fs &lt;- map(.x, function(x) {\n    future(.f(x))\n  })\n  map_dbl(fs, value)\n}\n\n\nBy now, you probably have one map() and one map_dbl() inside your function. It is helpful to point out that it is the map_dbl() one that makes parallel_map_dbl() emulate what purrr::map_dbl() does. The other map() is just used to create our futures and put them in a list. We could equally well use lapply() for that. We could even use a for loop as we used in Lab 1. Because of this, all of the following alternative solutions work equally well:\n\n\nSolution 1\n\n\nparallel_map_dbl &lt;- function(.x, .f) {\n  fs &lt;- purrr::map(.x, function(x) {\n    future(.f(x))\n  })\n  purrr::map_dbl(fs, value)\n}\n\n\n\n\nSolution 2\n\n\nparallel_map_dbl &lt;- function(.x, .f) {\n  fs &lt;- lapply(.x, function(x) {\n    future(.f(x))\n  })\n  purrr::map_dbl(fs, value)\n}\n\n\n\n\nSolution 3\n\n\nparallel_map_dbl &lt;- function(.x, .f) {\n  fs &lt;- list()\n  for (ii in seq_along(X)) {\n    x &lt;- .x[[ii]]\n    fs[[ii]] &lt;- future(.f(x))\n  }\n  purrr::map_dbl(fs, value)\n}\n\n\n\n\nThings that are problematic\nTask 3:\nRun the following:\n\nxs &lt;- list(1:25, 26:50, 51:75, 76:100)\nys &lt;- list()\npurrr::map(seq_along(xs), function(ii) {\n  ys[[ii]] &lt;- slow_sum(xs[[ii]])\n})\nys\n\nWhy doesn’t it work?\nTask 4:\nDo you think the following can be parallelized?\n\nys &lt;- list(0)  # initialize with zero\nfor (ii in 2:length(xs)) {\n  x &lt;- xs[[ii]]\n  y &lt;- ys[[ii - 1]]\n  ys[[ii]] &lt;- slow_sum(x + y)\n}\n\n\n\n\n\n\n\n\nPause here!\n\n\n\nLet’s pause here! Please let the tutor know when you got here.\n\n\n\n\n\nErrors and parallel processing\nThe Futureverse has been designed such that your experience running parallel code will be as close as possible to when you run regular, sequential code. For example, if we call:\n\nx &lt;- \"1.2\"\ny &lt;- log(x)\n\nError in log(x): non-numeric argument to mathematical function\n\n\nwe get an error.\nTask 5:\nTry the with a future() call and a value() call. Start by calling:\n\nf &lt;- future(log(x))\n\nDid you get an error or not? What could be the reason for that?\n\nNext, ask for the value of the future;\n\ny &lt;- value(f)\n\nWhat happens?\n\nTask 6:\nAsk for the value one more time;\n\ny &lt;- value(f)\n\nWhat happens now? What if you keep calling value(f) over and over?\nTask 7:\nIf we use purrr as in:\n\nlibrary(purrr)\n\nxs &lt;- list(\"1.2\", 42, 3.14)\ny &lt;- map_dbl(xs, log)\n\nError in `map_dbl()`:\nℹ In index: 1.\nCaused by error:\n! non-numeric argument to mathematical function\n\n\nwe get an error, because the first element of the xs list holds a string instead of a numeric value. That is what the error message tries to explain to us.\nLet’s try with furrr and future_map_dbl() function from above.\n\nlibrary(furrr)\nplan(multisession, workers = 4)\n\nxs &lt;- list(\"1.2\", 42, 3.14)\ny &lt;- future_map_dbl(xs, log)\n\nDoes it behave as you expected? Do you notice anything different? If so, let’s talk about it.\n\n\n\n\n\n\nNote\n\n\n\nAt first, it might appear obvious that we should get an error in these cases and that it will look the same as when running regular sequential code. But rest assured, Futureverse is the only parallel framework that behave this way. If you use one of the traditional frameworks you will get a different type of error, or not an error at all. This is the case for parLapply() and mclapply() of parallel. \n\n\nTask 8:\nNext, try the same but with mclapply() of the parallel package;\n\nlibrary(parallel)\n\nxs &lt;- list(\"1.2\", 42)\nys &lt;- mclapply(xs, log)\nprint(ys)\n\nWhat happened - did you get an error? With the behavior you observed, would you be able figure out what is wrong? Also, what is the risk with the current behavior?\nTask 9:\nNext, try the same but with parLapply() of the parallel package;\n\nlibrary(parallel)\nworkers &lt;- makeCluster(4)\n\nxs &lt;- list(\"1.2\", 42)\nys &lt;- parLapply(xs, log, cl = workers)\nprint(ys)\n\nstopCluster(workers)\n\nWhat happened - did you get an error? With the behavior you observed, would you be able figure out what is wrong?\n\n\nWarnings and parallel processing\nJust like errors, warnings are signalled as-is when parallelizing via futures.\nTask 10:\n\nlibrary(furrr)\nplan(multisession, workers = 4)\n\nxs &lt;- list(42, -1.2, 3.14)\nys &lt;- future_map(xs, log)\nys\n\nDid you get a warning?\nTask 11:\nTry the same with mclapply();\n\nlibrary(parallel)\nxs &lt;- list(42, -1.2, 3.14)\nys &lt;- mclapply(xs, log)\nys\n\nDid you get a warning?\nThen, try with parLapply();\n\nlibrary(parallel)\nworkers &lt;- makeCluster(4)\nxs &lt;- list(42, -1.2, 3.14)\nys &lt;- parLapply(xs, log, cl = workers)\nys\nstopCluster(workers)\n\nDid you get a warning?\n\n\n\n\n\n\nNote\n\n\n\nFutureverse is the only parallel framework that relays errors, warnings, messages, and output from parallel workers wherever they run in the world back to your R console.\n\n\n\n\n\n\n\n\n\nPause here!\n\n\n\nLet’s pause here! Please let the tutor know when you got here.\n\n\n\n\n\nProgress updates\nYou can generate progress updates using the progressr package.\nTask 12:\nCreate the following:\n\nlibrary(progressr)\n\nslow_sum &lt;- function(x) {\n  p &lt;- progressor(along = x)  ## create progressor of length(x)\n  \n  sum &lt;- 0\n  for (value in x) {\n    p()                       ## signal progress\n    Sys.sleep(1.0)\n    sum &lt;- sum + value\n  }\n  \n  sum\n}\n\nThen call:\n\ny &lt;- slow_sum(1:5)\n\nWhat happened?\nTask 13:\nNothing happened, because we never told progressr we, as end-users, are interested in the progress updates. To do that, we need to “subscribe” to the progress events, which we can do by calling:\n\nprogressr::handlers(global = TRUE)\n\nonce at the top of our R script.\nAfter this, retry with:\n\ny &lt;- slow_sum(1:5)\n\nTask 14:\nIf you run R from RStudio, the default progress bar is reported using the built-in RStudio progress bar. If you run R from the terminal or in VSCode, the default progress report uses an old-fashioned progress bar that is built-in to R. We could tweak it to be a little bit more colorful:\n\nprogressr::handlers(\n  progressr::handler_txtprogressbar(char = cli::col_red(cli::symbol$heart))\n)\n\nand call\n\ny &lt;- slow_sum(1:5)\n\nTask 15:\nThere are other ways to report on progress too. The cli package generates colorful, nice looking progress bars in the terminal. Try with:\n\nprogressr::handlers(\"cli\")\n\nTask 16:\nLet’s try to re-customize the default cli progress bar, e.g.\n\nprogressr::handlers(\n  progressr::handler_cli(format = \"{cli::pb_spin} {cli::pb_bar} {cli::pb_current}/{cli::pb_total} {cli::pb_status}\")\n)\n\nand call\n\ny &lt;- slow_sum(1:5)\n\nTask 17:\nThus far we have done progress reporting when running sequentially, but progressr works also when running in parallel using Futureverse.\nLet’s start by creating a utility function:\n\nslow_sum_all &lt;- function(xs) {\n  p &lt;- progressr::progressor(along = xs)\n  y &lt;- furrr::future_map_dbl(xs, function(x) {\n    sum &lt;- slow_sum(x)\n    p()\n    sum\n  })\n  sum(y)\n}\n\nthat we can use as:\n\nxs &lt;- list(1:10, 11:40, 41:60, 61:100)\ny &lt;- slow_sum_all(xs)\ny\n\nNow, run it in parallel with two parallel workers. Pay attention to processing time and progress bar.\nTask 18:\nRetry with four parallel workers. Then go back to sequential processing."
  },
  {
    "objectID": "lab1.html",
    "href": "lab1.html",
    "title": "Lab: Futureverse 1",
    "section": "",
    "text": "Note\n\n\n\nThis is the first of two parallelization labs. It will take you through some basic steps to parallelize your code using Futureverse. It focuses on core functions future() and value() for the purpose of illustrating what happens behind the scenes when we parallelize R code.\nYou are highly encouraged to test things out yourself and tweak things to figure out how these methods behave.\nSlides: You’ll find the slides in the menus above."
  },
  {
    "objectID": "lab1.html#install",
    "href": "lab1.html#install",
    "title": "Lab: Futureverse 1",
    "section": "Install",
    "text": "Install\nWe will start out by installing common Futureverse packages part of the Futureverse. We will not need them all in this lab, but it is convenient to have them all installed already now.\n\ninstall.packages(\"futureverse\")"
  },
  {
    "objectID": "lab1.html#exercises",
    "href": "lab1.html#exercises",
    "title": "Lab: Futureverse 1",
    "section": "Exercises",
    "text": "Exercises\nIn order to illustrate parallelization, we need two things: (i) a way to measure time, and (ii) something that takes at least a few seconds to run.\nTask 1:\nCopy and paste the following two code blocks.\nCreate functions tic() and toc() to measure time:\n\ntic &lt;- function() {\n  tic_start &lt;&lt;- base::Sys.time()\n}\n\ntoc &lt;- function() {\n  dt &lt;- base::difftime(base::Sys.time(), tic_start)\n  dt &lt;- round(dt, digits = 1L)\n  message(paste(format(dt), \"since tic()\"))\n}\n\nThese functions can be used as a timer, e.g.\n\ntic()\nSys.sleep(1.5)\ntoc()\n\n\n\n1.5 secs since tic()\n\n\n\nSys.sleep(4.0)\ntoc()\n\n\n\n5.5 secs since tic()\n\n\nNext, create toy function slow_sum() for calculating the sum of a vector really slowly:\n\nslow_sum &lt;- function(x) {\n  sum &lt;- 0\n  for (value in x) {\n    Sys.sleep(1.0)     ## one-second slowdown per value\n    sum &lt;- sum + value\n  }\n  sum\n}\n\nThis function works just like sum(), but it is very slow. If we use it to calculate \\(1 + 2 + \\ldots + 10\\), it will takes us ten seconds to get the result;\n\ntic()\ny &lt;- slow_sum(1:10)\ny\ntoc()\n\nMake sure you can run the latter, that it takes ten seconds to complete and that it returns the correct value.\nWe are now ready to get rolling!\n\nSimple parallel tasks\nAt the very core of Futureverse is the future package. Let us start out by loading this core package:\n\nlibrary(future)\n\nIt provides us with the fundamental building blocks for running R code in parallel; functions future(), value(), and resolved(). Other Futureverse packages, such as future.apply, furrr, and doFuture, rely on these three functions to build up more feature-rich functions. We will return to those later, but for now we will focus on future() and value().\nTask 2:\nLet’s start by writing our initial example using futures:\n\ntic()\nf &lt;- future(slow_sum(1:10))\ny &lt;- value(f)\ntoc()\n\nConfirm that you get the correct result. Did it run faster?\n\nTask 3:\nAdd another toc() just after the future() call;\n\ntic()\nf &lt;- future(slow_sum(1:10))\ntoc()\ny &lt;- value(f)\ntoc()\ny\ntoc()\n\nHow long did the creation of the future take?\n\nTask 4:\nBy design, Futureverse runs everything sequentially by default. We can configure it run code in parallel using two background workers as:\n\nplan(multisession, workers = 2)\n\nMake this change, and rerun the above example. Did the different steps take as long as you expected? What do you think the reason is for the change?\n\nTask 5:\nLet’s calculate \\(1 + 2 + \\ldots + 10\\) in two steps: (a) \\(1 + 2 +\n\\ldots + 5\\) and (b) \\(6 + 7 + \\ldots + 10\\), and then sum the two results.\n\nfa &lt;- future(slow_sum(1:5))\nfb &lt;- future(slow_sum(6:10))\ny &lt;- value(fa) + value(fb)\ny\n\nBut first, make sure to add toc() after each statement to better understand how long each step takes;\n\ntic()\nfa &lt;- future(slow_sum(1:5))\ntoc()\nfb &lt;- future(slow_sum(6:10))\ntoc()\ny &lt;- value(fa) + value(fb)\ntoc()\ny\ntoc()\n\nMake sure you get the expected result. Did it finish sooner? Which step takes the longest? Why do you think that is?\n\n\n\nCreate many parallel tasks via a for loop\nTask 6:\nHere is a very complicated way of calculating the sum \\(1 + 2 + \\ldots\n+ 20\\) in four chunks and outputting messages to show the progress:\n\ntic()\nxs &lt;- list(1:5, 6:10, 11:15, 16:20)\nys &lt;- list()\nfor (ii in seq_along(xs)) {\n  message(paste0(\"Iteration \", ii))\n  ys[[ii]] &lt;- slow_sum(xs[[ii]])\n}\nmessage(\"Done\")\nprint(ys)\n\nys &lt;- unlist(ys)\nys\n\ny &lt;- sum(ys)\ny\ntoc()\n\nRewrite it such that each iteration is parallelized via a future. Use four parallel workers as in:\n\nlibrary(future)\nplan(multisession, workers = 4)\n\n\nTask 7:\nRetry with three parallel workers as in:\n\nlibrary(future)\nplan(multisession, workers = 3)\n\nDid you notice something? What do you think happened?\n\n\nOur own parallel lapply\nTask 8:\nAbove, you used a for-loop to parallelize tasks. See if you can achieve the same using lapply() instead.\nTask 9:\nTake your parallel lapply() code and wrap it up in a function parallel_lapply() that takes two arguments X and FUN so that we can call:\n\nlibrary(future)\nplan(multisession)\n\nxs &lt;- list(1:5, 6:10, 11:15, 16:20)\n\nys &lt;- parallel_lapply(xs, slow_sum)\nys &lt;- unlist(ys)\ny &lt;- sum(ys)\n\n\n\nSolution\n\nparallel_lapply &lt;- function(X, FUN) {\n  ## Create futures that calls FUN(X[[1]]), FUN(X[[2]]), ...\n  fs &lt;- lapply(X, function(x) {\n    ## For element 'x', create future that calls FUN(x)\n    future(FUN(x))\n  })\n  \n  ## Collect the values from all futures\n  value(fs)\n}"
  }
]