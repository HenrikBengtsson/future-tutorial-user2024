---
title: "Lab: Futureverse 2"
author: "Henrik Bengtsson"
description: "Speed up your code through parallel computing"
image: "assets/featured.jpg"
format: html
---

```{r, echo = FALSE}
task_count <- 0L
task <- function() {
  task_count <<- task_count + 1L
  task_count
}
```

```{r, echo = FALSE}
## Allow workers = 4, even if we only have access to two cores
options(parallelly.maxWorkers.localhost = c(Inf, Inf))
```

::: {.callout-note}

This is the second of two parallelization labs. It will take you
through **[Futureverse]** functions that you and others are likely to
use to parallelize R code.  We will cover the **future.apply**
package, **furrr** package, and **foreach** with the **doFuture**
package. _In your R career, you can pick whichever you prefer - they
are all equally good._

You are highly encouraged to test things out yourself and tweak things
to figure out how these methods behave.

Slides: _You'll find the slides in the menus above._

:::



## Setup

It is assumed that you have already installed common Futureverse
packages in Lab 1.  In this second part, we will use a
not-so-slow-but-still-slow version of `slow_sum()`;

```{r}
library(future)
library(progressr)

slow_sum <- function(x) {
  sum <- 0
  for (value in x) {
    Sys.sleep(0.1)     ## 0.1 second slowdown per value
    sum <- sum + value
  }
  sum
}
```


```{r, echo = FALSE}
slow_sum <- base::sum
```


## Exercises

### Recap from Lab 1

In the first part - Lab 1 - we learned about the `future()` and
`value()` functions part of the **[future]** package.  They allow us
to run independent tasks like:

```{r}
xs <- list(1:25, 26:50, 51:75, 76:100)
a <- slow_sum(xs[[1]])
b <- slow_sum(xs[[2]])
c <- slow_sum(xs[[3]])
d <- slow_sum(xs[[4]])
y <- a + b + c + d
y
```

in parallel. We learned how to do:

```{r}
library(future)
plan(multisession, workers = 4)

xs <- list(1:25, 26:50, 51:75, 76:100)
fa <- future(slow_sum(xs[[1]]))
fb <- future(slow_sum(xs[[2]]))
fc <- future(slow_sum(xs[[3]]))
fd <- future(slow_sum(xs[[4]]))
y <- value(fa) + value(fb) + value(fc) + value(fd)
y
```


We then learned how to generalize this to a for-loop, by realizing we
can do:

```{r}
library(future)
plan(multisession, workers = 4)

xs <- list(1:25, 26:50, 51:75, 76:100)

fs <- list()
fs[[1]] <- future(slow_sum(xs[[1]]))
fs[[2]] <- future(slow_sum(xs[[2]]))
fs[[3]] <- future(slow_sum(xs[[3]]))
fs[[4]] <- future(slow_sum(xs[[4]]))

ys <- list()
ys[[1]] <- value(fs[[1]])
ys[[2]] <- value(fs[[2]])
ys[[3]] <- value(fs[[3]])
ys[[4]] <- value(fs[[4]])

ys <- unlist(ys)
y <- sum(ys)
y
```

and then simplify as:

```{r}
library(future)
plan(multisession, workers = 4)

xs <- list(1:25, 26:50, 51:75, 76:100)

fs <- list()
for (ii in seq_along(xs)) {
  fs[[ii]] <- future(slow_sum(xs[[ii]]))
}

ys <- list()
for (ii in seq_along(fs)) {
  ys[[ii]] <- value(fs[[ii]])
}

ys <- unlist(ys)
y <- sum(ys)
y
```

We then got rid of the for-loops in the auxillary index `ii`, by using
`lapply()`:

```{r}
library(future)
plan(multisession, workers = 4)

xs <- list(1:25, 26:50, 51:75, 76:100)

fs <- lapply(xs, function(x) { future(slow_sum(x)) })
ys <- lapply(fs, value)

ys <- unlist(ys)
y <- sum(ys)
y
```

Finally, we turned this into a utility function:

```{r}
parallel_lapply <- function(X, FUN) {
  fs <- lapply(X, function(x) {
    future(FUN(x))
  })
  lapply(fs, value)
}
```

such that we can do:

```{r}
library(future)
plan(multisession, workers = 4)

xs <- list(1:25, 26:50, 51:75, 76:100)
ys <- parallel_lapply(xs, slow_sum)
ys <- unlist(ys)
y <- sum(ys)
y
```


### Parallel versions of purrr::map()

**Task `{r} task()`:**

Write a `parallel_map()` function that emulates what the `map()`
function of the **[purrr]** package does, while at the same time running
in parallel using futures. We want to create a parallel version of:

```{r}
library(purrr)
xs <- list(1:25, 26:50, 51:75, 76:100)
ys <- map(xs, slow_sum)
ys <- unlist(ys)
y <- sum(ys)
y
```

We want to use the same argument names as
[`map()`](https://purrr.tidyverse.org/reference/map.html);

```{r}
args(map)
```

so that users of our `parallel_map()` will feel at home. For
simplicity, you can ignore arguments `...` and `.progress`. So, let's
create a function:

```{r}
#| eval: false
parallel_map <- function(.x, .f) {
  ## something here
}
```

I recommend that you modify the existing `parallel_lapply()`. Verify
that it works with:

```{r}
#| eval: false
library(future)
plan(multisession, workers = 4)

xs <- list(1:25, 26:50, 51:75, 76:100)
ys <- parallel_map(xs, slow_sum)
ys <- unlist(ys)
y <- sum(ys)
y
```


<details>
<summary>Solution</summary>
```{r}
library(purrr)

parallel_map <- function(.x, .f) {
  fs <- map(.x, function(x) {
    future(.f(x))
  })
  map(fs, value)
}
```
</details>


```{r, echo=FALSE}
xs <- list(1:25, 26:50, 51:75, 76:100)
ys <- parallel_map(xs, slow_sum)
ys <- unlist(ys)
y <- sum(ys)
stopifnot(y == 5050)
```


**Task `{r} task()`:**

Just like `lapply()` and `map()` return list, `parallel_lapply()` and
`parallel_map()` return lists. But, as in our example, it's common
that one wants the _atomic vector_ version of it, which is why we do:

```{r}
ys <- unlist(ys)
ys
```

Having to call this each time is tedious and adds friction and noise
to our code.  When not parallelizing, we can use **purrr**'s
`map_dbl()` to achieve the same in a one go;

```{r}
library(purrr)
xs <- list(1:25, 26:50, 51:75, 76:100)
ys <- map_dbl(xs, slow_sum)
y <- sum(ys)
y
```

Write your own `parallel_map_dbl()` that achieves the same, but via
futures, so that you can run:

```{r}
#| eval: false
library(purrr)
xs <- list(1:25, 26:50, 51:75, 76:100)
ys <- parallel_map_dbl(xs, slow_sum)
y <- sum(ys)
y
```

_Hint: Don't use `unlist()` - instead make use of `map_dbl()`. But
think carefully where in your function you want to use `map_dbl()`._

<details>
<summary>Solution</summary>
```{r}
library(purrr)

parallel_map_dbl <- function(.x, .f) {
  fs <- map(.x, function(x) {
    future(.f(x))
  })
  map_dbl(fs, value)
}
```
</details>


By now, you probably have one `map()` and one `map_dbl()` inside your
function. It is helpful to point out that it is the `map_dbl()` one
that makes `parallel_map_dbl()` emulate what `purrr::map_dbl()` does.
The other `map()` is just used to create our futures and put them in a
list.  We could equally well use `lapply()` for that. We could even
use a for loop as we used in Lab 1.  Because of this, all of the
following alternative solutions work equally well:


<details>
<summary>Solution 1</summary>
```{r}
parallel_map_dbl <- function(.x, .f) {
  fs <- purrr::map(.x, function(x) {
    future(.f(x))
  })
  purrr::map_dbl(fs, value)
}
```
</details>

<details>
<summary>Solution 2</summary>
```{r}
parallel_map_dbl <- function(.x, .f) {
  fs <- lapply(.x, function(x) {
    future(.f(x))
  })
  purrr::map_dbl(fs, value)
}
```
</details>

<details>
<summary>Solution 3</summary>
```{r}
parallel_map_dbl <- function(.x, .f) {
  fs <- list()
  for (ii in seq_along(X)) {
    x <- .x[[ii]]
    fs[[ii]] <- future(.f(x))
  }
  purrr::map_dbl(fs, value)
}
```
</details>



### Things that are problematic

**Task `{r} task()`:**

Run the following:

```{r}
#| eval: false
xs <- list(1:25, 26:50, 51:75, 76:100)
ys <- list()
purrr::map(seq_along(xs), function(ii) {
  ys[[ii]] <- slow_sum(xs[[ii]])
})
ys
```

_Why doesn't it work?_


**Task `{r} task()`:**

_Do you think the following can be parallelized?_

```{r}
#| eval: false
ys <- list(0)  # initialize with zero
for (ii in 2:length(xs)) {
  x <- xs[[ii]]
  y <- ys[[ii - 1]]
  ys[[ii]] <- slow_sum(x + y)
}
```


---

::: {.callout-tip title="Pause here!"}

Let's pause here! Please let the tutor know when you got here.

:::

---


### Errors and parallel processing

The Futureverse has been designed such that your experience running
parallel code will be as close as possible to when you run regular,
sequential code. For example, if we call:

```{r, error = TRUE}
x <- "1.2"
y <- log(x)
```

we get an error.



**Task `{r} task()`:**

Try the with a `future()` call and a `value()` call. Start by calling:

```{r, error = TRUE}
#| eval: false
f <- future(log(x))
```

_Did you get an error or not? What could be the reason for that?_

<!-- We will not get an error until we collect the results, which only
happens when we try to get the value of `f`. -->

Next, ask for the value of the future;

```{r, error = TRUE}
#| eval: false
y <- value(f)
```

_What happens?_

<!-- Here we are requesting the value of `f`, which will trigger the
error to be signalled. -->


**Task `{r} task()`:**

Ask for the value one more time;

```{r, error = TRUE}
#| eval: false
y <- value(f)
```

_What happens now?_  What if you keep calling `value(f)` over and over?



**Task `{r} task()`:**

If we use **purrr** as in:

```{r, error = TRUE}
library(purrr)

xs <- list("1.2", 42, 3.14)
y <- map_dbl(xs, log)
```

we get an error, because the first element of the `xs` list holds a
string instead of a numeric value.  That is what the error message
tries to explain to us.

Let's try with **[furrr]** and `future_map_dbl()` function from above.

```{r, error = TRUE}
#| eval: false
library(furrr)
plan(multisession, workers = 4)

xs <- list("1.2", 42, 3.14)
y <- future_map_dbl(xs, log)
```

_Does it behave as you expected? Do you notice anything different? If
so, let's talk about it._



::: {.callout-note}

At first, it might appear obvious that we should get an error in these
cases and that it will look the same as when running regular
sequential code. But rest assured, Futureverse is the only parallel
framework that behave this way. If you use one of the traditional
frameworks you will get a different type of error, or not an error at
all. This is the case for `parLapply()` and `mclapply()` of
**parallel**.
<!--
as well as for `foreach()` and `%dopar%` of **foreach**.
-->

:::


**Task `{r} task()`:**

Next, try the same but with `mclapply()` of the **parallel**
package;

```{r, echo = FALSE}
suppressWarnings(rm(list = c("xs", "ys")))
```

```{r, error = TRUE}
#| eval: false
library(parallel)

xs <- list("1.2", 42)
ys <- mclapply(xs, log)
print(ys)
```

_What happened - did you get an error? With the behavior you observed,
would you be able figure out what is wrong?  Also, what is the risk
with the current behavior?_



**Task `{r} task()`:**

Next, try the same but with `parLapply()` of the **parallel** package;

```{r, echo = FALSE}
suppressWarnings(rm(list = c("xs", "ys")))
```

```{r, error = TRUE}
#| eval: false
library(parallel)
workers <- makeCluster(4)

xs <- list("1.2", 42)
ys <- parLapply(xs, log, cl = workers)
print(ys)

stopCluster(workers)
```

_What happened - did you get an error? With the behavior you
observed, would you be able figure out what is wrong?_



### Warnings and parallel processing

Just like errors, warnings are signalled as-is when parallelizing via
futures.

**Task `{r} task()`:**

```{r}
#| eval: false
library(furrr)
plan(multisession, workers = 4)

xs <- list(42, -1.2, 3.14)
ys <- future_map(xs, log)
ys
```

_Did you get a warning?_


**Task `{r} task()`:**

Try the same with `mclapply()`;

```{r}
#| eval: false
library(parallel)
xs <- list(42, -1.2, 3.14)
ys <- mclapply(xs, log)
ys
```

_Did you get a warning?_


Then, try with `parLapply()`;

```{r}
#| eval: false
library(parallel)
workers <- makeCluster(4)
xs <- list(42, -1.2, 3.14)
ys <- parLapply(xs, log, cl = workers)
ys
stopCluster(workers)
```

_Did you get a warning?_


::: {.callout-note}

Futureverse is the only parallel framework that relays errors,
warnings, messages, and output from parallel workers wherever they run
in the world back to your R console.

:::


---

::: {.callout-tip title="Pause here!"}

Let's pause here! Please let the tutor know when you got here.

:::

---


### Progress updates

You can generate progress updates using the **[progressr]** package.

**Task `{r} task()`:**

Create the following:

```{r}
library(progressr)

slow_sum <- function(x) {
  p <- progressor(along = x)  ## create progressor of length(x)
  
  sum <- 0
  for (value in x) {
    p()                       ## signal progress
    Sys.sleep(1.0)
    sum <- sum + value
  }
  
  sum
}
```

Then call:

```{r}
#| eval: false
y <- slow_sum(1:5)
```

_What happened?_


**Task `{r} task()`:**

Nothing happened, because we never told **progressr** we, as
end-users, are interested in the progress updates.  To do that, we
need to "subscribe" to the progress events, which we can do by
calling:

```{r}
#| eval: false
progressr::handlers(global = TRUE)
```

once at the top of our R script.

After this, retry with:

```{r}
#| eval: false
y <- slow_sum(1:5)
```


**Task `{r} task()`:**

If you run R from RStudio, the default progress bar is reported using
the built-in RStudio progress bar.  If you run R from the terminal or
in VSCode, the default progress report uses an old-fashioned progress
bar that is built-in to R.  We could tweak it to be a little bit more
colorful:

```{r}
#| eval: false
progressr::handlers(
  progressr::handler_txtprogressbar(char = cli::col_red(cli::symbol$heart))
)
```

and call

```{r}
#| eval: false
y <- slow_sum(1:5)
```


**Task `{r} task()`:**

There are other ways to report on progress too. The **[cli]** package
generates colorful, nice looking progress bars in the terminal.  Try
with:

```{r}
#| eval: false
progressr::handlers("cli")
```


**Task `{r} task()`:**

Let's try to re-customize the default **cli** progress bar, e.g.

```{r}
progressr::handlers(
  progressr::handler_cli(format = "{cli::pb_spin} {cli::pb_bar} {cli::pb_current}/{cli::pb_total} {cli::pb_status}")
)
```

and call

```{r}
#| eval: false
y <- slow_sum(1:5)
```


**Task `{r} task()`:**

Thus far we have done progress reporting when running sequentially,
but **progressr** works also when running in parallel using
Futureverse.

Let's start by creating a utility function:

```{r}
slow_sum_all <- function(xs) {
  p <- progressr::progressor(along = xs)
  y <- furrr::future_map_dbl(xs, function(x) {
    sum <- slow_sum(x)
    p()
    sum
  })
  sum(y)
}
```

that we can use as:

```{r}
#| eval: false
xs <- list(1:10, 11:40, 41:60, 61:100)
y <- slow_sum_all(xs)
y
```

_Now, run it in parallel with two parallel workers. Pay attention to
processing time and progress bar._


**Task `{r} task()`:**

_Retry with four parallel workers. Then go back to sequential
processing._


[Futureverse]: https://www.futureverse.org/
[future]: https://future.futureverse.org/
[progressr]: https://progressr.tidyverse.org/
[purrr]: https://purrr.tidyverse.org/
[furrr]: https://furrr.futureverse.org/
[cli]: https://cli.r-lib.org/
